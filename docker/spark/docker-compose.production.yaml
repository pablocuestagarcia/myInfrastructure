services:
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    hostname: spark-master
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_NO_DAEMONIZE=true
    ports:
      - '8080:8080'
      - '7077:7077'
      - '4040-4050:4040-4050'
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ./spark-events:/opt/spark/spark-events
      - ./jars:/opt/spark/extra-jars
      - ./conf:/opt/spark/conf
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8080']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  spark-worker-1:
    image: apache/spark:3.5.0
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077"
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=6g
      - SPARK_WORKER_WEBUI_PORT=8881
      - SPARK_NO_DAEMONIZE=true
    ports:
      - '8881:8881'
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ./spark-events:/opt/spark/spark-events
      - ./jars:/opt/spark/extra-jars
      - ./conf:/opt/spark/conf
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    depends_on:
      spark-master:
        condition: service_healthy
    restart: unless-stopped

  spark-worker-2:
    image: apache/spark:3.5.0
    container_name: spark-worker-2
    hostname: spark-worker-2
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077"
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=6g
      - SPARK_WORKER_WEBUI_PORT=8882
      - SPARK_NO_DAEMONIZE=true
    ports:
      - '8882:8882'
    volumes:
      - ./spark-apps:/opt/spark-apps
      - ./spark-data:/opt/spark-data
      - ./spark-events:/opt/spark/spark-events
      - ./jars:/opt/spark/extra-jars
      - ./conf:/opt/spark/conf
    networks:
      - spark-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    depends_on:
      spark-master:
        condition: service_healthy
    restart: unless-stopped

  spark-history:
    image: apache/spark:3.5.0
    container_name: spark-history
    hostname: spark-history
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events -Dspark.history.ui.port=18080
      - SPARK_NO_DAEMONIZE=true
    ports:
      - '18080:18080'
    volumes:
      - ./spark-events:/opt/spark/spark-events
    networks:
      - spark-network
    depends_on:
      - spark-master
    restart: unless-stopped

networks:
  spark-network:
    driver: bridge
    name: spark-network
